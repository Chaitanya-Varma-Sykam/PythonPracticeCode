{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "hMqWDc_m6rUC"
   },
   "source": [
    "This is a modified version of a notebook created by Google. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with [this License](https://www.apache.org/licenses/LICENSE-2.0). **Copyright 2017 Google LLC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHLcriKWLRe4"
   },
   "source": [
    "# Intro to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QvJBqX8_Bctk"
   },
   "source": [
    "**Learning Objectives:**\n",
    "  * Gain an introduction to the `DataFrame` and `Series` data structures of the *pandas* library\n",
    "  * Access and manipulate data within a `DataFrame` and `Series`\n",
    "  * Import CSV data into a *pandas* `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIFJ83ZTBctl"
   },
   "source": [
    "As noted on the website, [*pandas*](http://pandas.pydata.org/) \"is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\"  It's a great tool for handling and analyzing input data, and many ML frameworks support *pandas* data structures as inputs (for example, you can pass a *pandas* dataframe to the `train_test_split()` function of *sci-kit learn*.\n",
    "\n",
    "Although a comprehensive introduction to the *pandas* would span many pages, the core concepts are fairly straightforward, and we'll present them below. For a more complete reference, the [*pandas* docs site](http://pandas.pydata.org/pandas-docs/stable/index.html) contains extensive documentation and many tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_JOISVgmn9v"
   },
   "source": [
    "## Basic Concepts\n",
    "\n",
    "The following line imports the *pandas* package and prints the version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aSRYu62xUi3g",
    "outputId": "3dd8cf4a-4b2f-4906-cfda-048c631bc35d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daQreKXIUslr"
   },
   "source": [
    "The primary data structures in *pandas* are implemented as two classes:\n",
    "\n",
    "  * **`DataFrame`**, which you can imagine as a relational data table, with rows and named columns.\n",
    "  * **`Series`**, which is a single column. A `DataFrame` contains one or more `Series` and a name for each `Series`.\n",
    "\n",
    "The data frame is a commonly used abstraction for data manipulation. Similar implementations exist in [Spark](https://spark.apache.org/) and [R](https://www.r-project.org/about.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjnAk1xcU0yc"
   },
   "source": [
    "One way to create a `Series` is to construct a `Series` object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "DFZ42Uq7UFDj",
    "outputId": "a647ae21-2650-4672-fe2a-9bb927096b0f"
   },
   "outputs": [],
   "source": [
    "pd.Series(['San Francisco', 'San Jose', 'Sacramento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5ouUp1cU6pC"
   },
   "source": [
    "`DataFrame` objects can be created by passing a `dict` mapping `string` column names to their respective `Series` (see [Dictionary section](https://www.learnpython.org/en/Dictionaries) of *learnpython.org*). Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "avgr6GfiUh8t",
    "outputId": "6c8f154f-0256-4ab9-cc89-57e181c6ec50"
   },
   "outputs": [],
   "source": [
    "city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento'])\n",
    "population = pd.Series([852469, 1015785, 485199])\n",
    "\n",
    "cities = pd.DataFrame({ 'City name': city_names, 'Population': population })\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `Series` don't match in length, missing values are filled with special [NA/NaN](http://pandas.pydata.org/pandas-docs/stable/missing_data.html) values. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "avgr6GfiUh8t",
    "outputId": "6c8f154f-0256-4ab9-cc89-57e181c6ec50"
   },
   "outputs": [],
   "source": [
    "city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento', 'New York']) # 4 cities\n",
    "population = pd.Series([852469, 1015785, 485199])                               # only 3 values\n",
    "\n",
    "cities_NA = pd.DataFrame({ 'City name': city_names, 'Population': population })\n",
    "cities_NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oa5wfZT7VHJl"
   },
   "source": [
    "But most of the time, you load an entire file into a `DataFrame`. The following example loads a file with California housing data. Run the following cell to create a Pandas dataframe from a url: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "av6RYOraVG1V",
    "outputId": "cd94b607-3a1c-4ebf-ae63-03c578d8274f"
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "california_housing_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a Pandas dataframe from a local csv file (among other file types). For the following code to run, make sure that the csv file has been downloaded and is in the same folder as this notebook. If the csv file is somewhere else on your computer, then you will have to specify `\"/path/to/file/california_housing_train.csv\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing_dataframe = pd.read_csv(\"california_housing_train.csv\", sep=\",\")\n",
    "california_housing_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `DataFrame.info()` to show basic information about a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "wrsy_vDYrrnl",
    "outputId": "00a09d08-fbd8-4d43-afbd-83317d6b40f1"
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `DataFrame.describe()` to show interesting statistics about a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "CRG-gaOTr1v-",
    "outputId": "275b9a2c-520d-42ea-fade-fddc1e281be8"
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrkBjfz5kEQu"
   },
   "source": [
    "Another useful function is `DataFrame.head`, which displays the first few records of a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "s3ND3bgOkB5k",
    "outputId": "ef261973-ab57-4184-ee89-81a55dd2a783"
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `DataFrame.tail()` to see the last few records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing_dataframe.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9-Es5Y6laGd"
   },
   "source": [
    "Another powerful feature of *pandas* is graphing. For example, `DataFrame.hist` lets you quickly study the distribution of values in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "nqndFVXVlbPN",
    "outputId": "4ba017ed-fc99-4bab-ca5e-69fb22b41eec"
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe.hist('housing_median_age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9-Es5Y6laGd"
   },
   "source": [
    "And `DataFrame.plot.scatter` lets you quickly see a scatter plot for two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "vihLeGc6sSun",
    "outputId": "129390f2-fa1b-4eac-8474-8e7684bba261"
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe.plot.scatter('median_income', 'median_house_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-xAOJeMiXFB"
   },
   "source": [
    "## Indexes\n",
    "Both `Series` and `DataFrame` objects also define an `index` property that assigns an identifier value to each `Series` item or `DataFrame` row. \n",
    "\n",
    "By default, at construction, *pandas* assigns index values that reflect the ordering of the source data. Once created, the index values are stable; that is, they do not change when data is reordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2684gsWNinq9",
    "outputId": "d8e695b0-8583-4ef6-a156-74fe99bdf712"
   },
   "outputs": [],
   "source": [
    "city_names.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F_qPe2TBjfWd",
    "outputId": "475b8500-4053-41ae-af98-cf2ce322bdeb"
   },
   "outputs": [],
   "source": [
    "cities.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hp2oWY9Slo_h"
   },
   "source": [
    "Call `DataFrame.reindex` to manually reorder the rows. For example, the following has the same effect as sorting by city name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "sN0zUzSAj-U1",
    "outputId": "9172dcff-2298-4e44-dd98-0d8bab110ae8"
   },
   "outputs": [],
   "source": [
    "cities.reindex([2, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GQFz8NZuS06"
   },
   "source": [
    "Reindexing is a great way to shuffle (randomize) a `DataFrame`. In the example below, we take the index, which is array-like, and pass it to NumPy's `random.permutation` function, which shuffles its values in place. Calling `reindex` with this shuffled array causes the `DataFrame` rows to be shuffled in the same way.\n",
    "Try running the following cell multiple times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "mF8GC0k8uYhz",
    "outputId": "b750607e-389c-4f19-a790-036c338f834f"
   },
   "outputs": [],
   "source": [
    "# run this code a few times and note the change in order of the rows\n",
    "\n",
    "random_order = np.random.permutation(cities.index)\n",
    "print(\"\\nNew random order for rows is {}\\n\".format(random_order))\n",
    "\n",
    "cities.reindex(random_order) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSso35fQmGKb"
   },
   "source": [
    "For more information, see the [Index documentation](http://pandas.pydata.org/pandas-docs/stable/indexing.html#index-objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtYZ7114n3b-"
   },
   "source": [
    "## Accessing Data\n",
    "\n",
    "The three primary ways of accessing data in a Pandas dataframe are `[]`, `.loc`, and `.iloc`. To see how these work, let's load a subset of the `iris` dataset, contained in the `iris_data.csv` file that accompanies this notebook. We will also change the index so it's a bit easier to see what is going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris_data.csv\")\n",
    "\n",
    "# Don't worry about the two lines of code here\n",
    "# just take a look at the output and note that the \"index\" column gives the labels 'a', 'b', 'c', etc. to the rows\n",
    "# of the data frame. Normally, the labels for the rows are '0', '1', '2', etc.\n",
    "iris['index'] = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'f']\n",
    "iris.set_index(keys='index', inplace=True, drop=True)\n",
    "\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `[]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"sepal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting two or more columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[ [\"sepal_width\", \"petal_width\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting multiple rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[0:2] # Note that 0:2 denotes position, so we are selecting the first (0) and second (1) rows; remember that Python indexing start from 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.loc`\n",
    "\n",
    "The `.loc` method selects rows and columns by **label**, that is, by name. This is used in the form: `DataFrame.loc[row labels, column labels]`. \n",
    "\n",
    "Note that the colon `:` means select all rows and/or all columns, depending on where you place it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc['a', : ] # selects the row labeled 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[ ['a', 'e', 'h'], :] # selects the rows labeled 'a', 'e', and 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[:, 'sepal_width'] # selects the column labeled 'sepal_width'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[:, ['sepal_length', 'petal_width']] # selects the columns labeled 'sepal_length' and 'petal_width'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[ ['a', 'e'], ['sepal_width', 'petal_width']] # selects the rows labeled 'a' and 'e' and the columns labeled 'sepal_width' and 'petal_width'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.iloc`\n",
    "\n",
    "The `.iloc` method selects rows and columns by **position**. This is used in the form: `DataFrame.loc[row positions, column positions]`. \n",
    "\n",
    "Note that the colon `:` means select all rows and/or all columns, depending on where you place it. \n",
    "\n",
    "Let's reproduce what we did with `.loc` but with `.iloc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[0, : ] # selects the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[ [0, 4, 7], :] # selects the first, fifth, and eight rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[:, 1] # selects the second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[:, [0, 3]] # selects the first and fourth columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[ [0, 4], [1, 3]] # selects the first and fifth rows and the second and fourth columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65g1ZdGVjXsQ"
   },
   "source": [
    "In addition, *pandas* provides an extremely rich API for advanced [indexing and selection](http://pandas.pydata.org/pandas-docs/stable/indexing.html) that is too extensive to be covered here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Data\n",
    "\n",
    "You may apply Python's basic arithmetic operations to `Series` or columns. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "XWmyCFJ5bOv-",
    "outputId": "e7854b61-3f21-4901-a12a-dc7a7bf7287e"
   },
   "outputs": [],
   "source": [
    "iris['sepal_length'] * 100.  # convert cm to meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQzIVnbnmWGM"
   },
   "source": [
    "[NumPy](http://www.numpy.org/) is a popular toolkit for scientific computing. *pandas* `Series` can be used as arguments to most NumPy functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ko6pLK6JmkYP",
    "outputId": "5c3b6f27-7b50-475d-8079-b0c0d2c9ab89"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.log(iris['petal_width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmxFuQmurr6d"
   },
   "source": [
    "We also do more complex operations. The example below creates a new `Series` that indicates whether `sepal_width` is greater than 3.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Fc1DvPAbstjI",
    "outputId": "09449123-d72b-433f-b117-31e01a17cb3c"
   },
   "outputs": [],
   "source": [
    "iris['sepal_width'] > 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the output from the above to subset our dataframe based on the specified condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[ iris['sepal_width'] > 3.2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation above only keeps the rows where our condition, `sepal_width > 3.2` is `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeYYLoV9b9fB"
   },
   "source": [
    "\n",
    "Modifying `DataFrames` is also straightforward. For example, the following code adds two `Series` to an existing `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "0gCEX99Hb8LR",
    "outputId": "4c7cf913-298b-4923-b54a-8eda39ce2e37"
   },
   "outputs": [],
   "source": [
    "iris['sepal_ratio'] = iris['sepal_length'] / iris['sepal_width']\n",
    "iris['petal_ratio'] = iris['petal_length'] / iris['petal_width']\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with Scikit-Learn (OPTIONAL)\n",
    "\n",
    "In this section we will just give a brief example of a couple ways that Pandas dataframes integrate with the scikit-learn API. **We have not yet learned about some of the code, models, and steps that are included here, but it may be a worth just reading through and executing the code and looking at the output and thinking about what may be going on. You may not understand any or all of it at this point, but that's ok.**\n",
    "\n",
    "### Using Dataframes directly\n",
    "\n",
    "Here, we will specify which columns we want to keep as our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "X_df = iris[ feature_columns ]\n",
    "\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And which column is our target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create train and test sets directly from the Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use to create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do this is to extract a NumPy array from the dataframe and then use those arrays as we have been doing up until now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = X_df.values\n",
    "\n",
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = y.values\n",
    "\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_array)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JndnmDMp66FL",
    "YHIWvc9Ms-Ll",
    "TJffr5_Jwqvd"
   ],
   "name": "Lab_1_intro_to_pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
